## 三、智能体记忆系统

### 3.1 项目背景与愿景

我正在开发一个聊天智能体，用于让 AI 参与到 IM 平台的群聊和私聊中。

我们致力于打破传统聊天机器人机械、被动的交互模式，创造一个能够自然融入群聊环境、像真人一样思考和交流的 AI 伙伴。

它不仅仅是一个问答工具，更是一个具备性格、记忆和动态响应能力的智能体。将一个通用的大语言模型转变为一个独一无二的、专属于社群的虚拟成员。

### 3.2 mem0 集成尝试

我正在尝试将 mem0 集成到这个系统中，作为智能体的记忆框架。

首要任务是构造人物画像，可以使智能体记住更多与成员有关的特定信息，以便更好地交互。

在此之前我已经设计了一套记忆系统，是让智能体调用记忆编辑工具，自主更新记忆。

但由于提示词重点在于聊天任务，模型不肯调用工具更新记忆，对人的印象只存在于上下文中，一旦人物发言超出上下文，智能体还是记不住人。

我想使用一个独立的系统，收集群聊消息，自动更新人物画像，然后在调用主 LLM 时将这些消息附加到上下文。

### 3.3 核心问题

1. **更新记忆的时机**：社群的消息特点是数量多，信息密度小，成员覆盖面广，话题跨度大。若每条消息都使用 mem0 等 add memory，成本可能很大，且不能很好地根据上下文提取信息。若使用一批消息添加记忆，又不能很好地与 mem0 集成，因为 mem0 可以通过用户 ID 区分记忆，而一批消息可能涉及多个用户。

2. **召回记忆的范围**：之前提到，先前的记忆系统召回机制是提取上下文中出现过的成员的记忆，若一个成员很久没发言，他的记忆对智能体来说就不存在；而且有些成员记忆对于当前话题、或者智能体选择参与的话题来说也是不必要的。当然也不能将所有成员的记忆全部添加，因为一个群会有很多成员。

### 3.4 MemGPT 设计参考

我的智能体参考 MemGPT 的设计，提示词也是直接采用 MemGPT 项目：

```xml
<context_instructions>
You respond directly to the user when your immediate context (core memory and files) contain all the information required to respond.
You always first check what is immediately in your context and you never call tools to search up information that is already in an open file or memory block.
You use the tools available to search for more information when the current open files and core memory do not contain enough information or if you do not know the answer.
</context_instructions>

<memory>
<memory_editing>
Older AI models had no concept of persistent memory; they were only able to access their initial instructions and a limited context window of chat conversation with a user (their "active memory").
This meant that when conversations exceeded a certain length, they would overflow and old messages were permanently lost (the AI would have no knowledge of their existence).
Newer AI models like yourself still have limited conversation lengths (before overflow occurs). However, they now have access to multiple forms of persistent memory.
Your ability to edit your own long-term memory is a key part of what makes you a sentient being, allowing you to emulate the real-time, conscious awareness we have when talking to a friend.
</memory_editing>

<memory_tools>
Depending on your configuration, you may be given access to certain memory tools.
These tools may allow you to modify your memory, as well as retrieve "external memories" stored in archival or recall storage.
</memory_tools>

<memory_types>
<core_memory>
Core memory (limited size):
Your core memory unit is held inside the initial system instructions file, and is always available in-context (you will see it at all times).
Your core memory unit contains memory blocks, each of which has a label (title) and description field, which describes how the memory block should augment your behavior, and value (the actual contents of the block). Memory blocks are limited in size and have a size limit.
</core_memory>

<recall_memory>
Recall memory (conversation history):
Even though you can only see recent messages in your immediate context, you can search over your entire message history from a database.
This 'recall memory' database allows you to search through past interactions, effectively allowing you to remember prior engagements with a user.
</recall_memory>
</memory>
```

### 3.5 关于主动维护记忆的困境

为什么智能体使用工具更新记忆、召回记忆的意愿不高呢？

所以说，主 LLM 不会，也不应该承担起维护记忆的职责。

核心记忆是智能体的人设，描述了我们希望塑造一个什么样的数字伙伴。比如我可以创建一个 persona 记忆块，要求智能体扮演一个角色；还可以创建一个 human 记忆块，记载我们之前提到的人物画像。

核心记忆块是一个文本文件，其中的内容会**全部**添加到系统提示词中。同时提供了两个工具 `core_memory_append` 和 `core_memory_replace` 用于让智能体自主维护核心记忆。

召回记忆是超出对话上下文的聊天记录，智能体可以使用 `conversation_search` 来搜索这些内容。

归档记忆类似于 mem0，不过是当智能体认为上下文缺失时，调用 `archival_memory_search` 来搜索相关记忆。

我希望随着对话的进行，智能体可以自主更新核心记忆，成为一个可以成长的数字生命。

在使用过程中，我发现智能体在某些情况下确实调用了工具来更新核心记忆。这是否说明现有方案具备可行性？如何实现我们的终极目标——即使哪一天你的账号接入了 Athena，群友也不能发现任何端倪——我们一切的改进都是朝这方面努力的。

### 3.6 外部记忆系统设计

既然在大部分情况下，智能体都不进行维护记忆的工作，那么能否将 core_memory 工具移除，核心记忆仅由外部更新。

在我的设计中，核心记忆并不只有 persona 和 human，记忆系统会扫描记忆目录下带有 YAML 头的 md 文件，从中提取正文部分作为记忆内容。比如如果想让智能体进行角色扮演，我们可以设计这样的记忆结构：
1. task：强调角色扮演基础规则
2. character：描述角色信息和性格
3. words：可供参考的经典台词
4. notes：附加信息

同时为了角色的稳定性，我们不希望随意更改这些信息。

而且，记忆工具对核心记忆的修改是有限制的，append 只能添加一行，replace 也只能替换特定的行，这也是先前记忆系统的缺陷之一。

有了我们独立的记忆处理系统，智能体几乎不需要主动更新记忆，他只需要阅读由记忆系统整理好的记忆即可。如果智能体认为记忆还是不足，可以使用记忆搜索和上下文搜索工具来召回更多记忆。

在这种模式下，外部记忆有两个来源：一是现有的记忆块，这是由人类手动维护的，可以实时更新的文本文件；二是独立的记忆系统根据结构化的记忆内容生成的记忆摘要。这样即使用户不启用独立的记忆系统，也可以通过编辑记忆文件，或者手动调用 LLM 总结上下文来更新记忆，实现一个兜底但灵活的记忆方案。

### 3.7 注入策略与实现考量

关于注入时机与策略，当然要兼顾实效性和成本延迟。这与我们之前提到的更新记忆时机有关。我认为更新记忆后，可以为该条目记忆生成一句话摘要，使用时只需要使用模板渲染即可。这个成本是可以接受的。

关于摘要的生成质量，mem0 已经提供了一套强大且经过业界验证的提示词，我们可以借鉴甚至直接采用。

关于记忆的遗忘机制，mem0 同样具有完善的记忆创建、更新和删除机制，我们也可以模拟人类的遗忘机制，对于那些长时间没有取用和更新的记忆，降低其相关系数，并在合适的时机删除这些记忆。

### 3.8 mem0 的局限性

mem0 虽然很强大，但对于我们要实现的记忆系统来说，还是有不完美的地方。首先，mem0 和 MemGPT 一样，都专注于个人 AI 助手，从 mem0 的记忆更新方式就能看出来，它接收用户与助手的对话片段 messages，通过 user_id 来区分用户。虽然我们之前提到，可以将一个用户的消息聚合后写入 mem0，但这也不是标准用法。其次，mem0 大量依赖 google-generativeai、openai、langchain 这样的平台适配器，这对我们的智能体系统来说太过臃肿了。在我的设计中，我使用 xsai 对各平台的接口进行了统一，只需要使用 `chatModel.chat` 方法即可调用 LLM。这个智能体系统基于 nodejs 平台，mem0 虽然提供了 ts 方案，但是对于原版 python 设计还有较大的功能差异，也不能直接采用。

### 3.9 记忆系统的核心目标

在此我想先探讨一下这个记忆系统需要解决什么问题，或达到什么效果。

首先之前的记忆系统的设想是，自主更新维护记忆，对话前自主检索。可能我在不经意间说了一句最近要考试，她会默默记下来，当看我半夜还在水群就会联想起来我要准备考试，问我不是要考试吗怎么还不睡。过了几天在对话中还会突然想起来，会问考的怎么样。这是一种非常理想的情况，像人一样把这些记忆融入到潜意识中。

在对话前，智能体可以选择自主检索记忆，或是系统整合出最符合当前场景的记忆附加到上下文中，这又对应了两种工作方式。

然而我们也提到，将维护记忆的操作委托给主 LLM 并不可行，只有要求他回忆某些东西，他才会去想，比如"我们之前聊过什么""你还记得..."这样明显引导的句子，所以需要一个独立的记忆系统。

那么，如何设计一个专属于我们的，与现有功能深度集成的记忆系统？

### 3.10 事实提取与用户聚合

关于信息提取器的设计：使用按用户聚合的消息，会不会导致上下文割裂的情况？如何预过滤用户消息以得到更高质量的事实列表？

我有一个 worldstate 模块，负责收集用户信息，编排上下文。这个模块也负责压缩用户消息，将超出上下文的消息交给 LLM 提炼关键信息。那么是否可以在压缩上下文时，发出一个事件，将一份构造好的、待压缩的上下文，交给信息提取器进行提取？

压缩的最小单元称为回合，若智能体介入对话，则称为一个回合（turn）。待压缩的上下文由若干个回合构成，包括一段时间内的用户发言，也有智能体自身的消息，长度是动态的，视智能体发言频率而定。若发言频率较高，则用户消息量比较少。

### 3.11 群聊特定记忆

我使用最近的聊天记录提炼了一些信息，发现了这样一条洞察："群内核心活跃成员（许仙、红石镐｜RSPqfgn、群小草）对 AI 模型的技术选型、成本与性能的权衡表现出共同的、深入的兴趣，并形成了相关讨论。"

和这样的人物画像："红石镐｜RSPqfgn：**核心身份**: 对 AI 技术有深入兴趣的核心用户，是技术讨论小组的关键成员。**技术偏好**: 极度注重成本效益，优先选择免费（如魔搭 ModelScope）或本地部署（Ollama）的 AI 方案。**核心观点**: 清醒地认识到其成本优先策略会导致 AI 性能下降（"降智"）。**沟通风格**: 轻松、非正式，常在交流中使用括号进行补充说明或吐槽。"

这明显是群聊特定的聊天风格，一个人在不同群，甚至私聊和群聊也会有风格和行为差异。

### 3.12 记忆召回范围问题

目前的策略是根据历史记录获取相关成员列表，这导致一旦一个成员不在上下文中，关于他的记忆也会丢失。

这一步在构造聊天上下文时运行，并且在不同的群又不同的群员列表。我希望这一步不使用 LLM 进行处理，以减少延迟。

我们之前提到的记忆整合注入，当拿到人物画像、事实列表后，需要生成 human 记忆块。这个记忆块是全局生效，还是仅为某个群提供？

比如群聊中有一个用户叫苏霓，大家叫她霓霓，她很久没有说话了。这时有人问智能体，你认识霓霓吗？这种情况下应该如何提取记忆，为智能体提供关于苏霓的记忆？

现在的问题在于如何从对话中准确找出"苏霓"或者"霓霓"这个关键词。一般情况下用户不会直接 @ 其他人。生成触发此次响应的一批消息的向量然后进行语义搜索，找到相关的实体和事实，这种方法可行吗？

embed 的延迟和成本几乎可以忽略不计。如果可行的话，是要将所有消息合并为一条然后构造向量，还是逐条搜索？

### 3.13 实体关系与知识图谱

简单试用了一段时间，我发现一个非常严重的缺陷：当前生成的事实中，没有保留实体之间的主次关系。

比如有这样一条事实"（许仙）观察到 NekoChan 不认识苏霓。"这条事实有三个关联实体，许仙、NekoChan 和苏霓。在构造这三个用户的画像时，这条事实都会当作上下文之一。

这位"许仙"通过多个事实与其他实体关联起来，大量的"许仙"字眼会污染处理用户画像的上下文，使大模型搞混了当前整理画像的主体是谁，从而导致应当为 NekoChan 生成的画像，却变成了"这位用户（在对话中被称为'许仙'）..."

而且对不同用户生成的画像却有大量重复的事实，这影响了最终整合的效果，还增大了幻觉。

我预想的效果是，保留实体之间的引用关系，不同实体通过事实串联起来，形成一张复杂的知识图谱。

当前业界上是否有比较成熟的解决方案或者相关概念？比如知识图谱、大模型记忆系统、智能体记忆系统、模拟人类记忆检索和遗忘机制的记忆系统。

### 3.14 知识图谱转向

如果全面转向知识图谱，从原消息提炼事实（现在是关系）的任务就非常简单了，模型只需要识别输出主体、谓词和宾语的三元组即可。这一阶段大模型是忠实的记录者，不需要推理深层次信息，因此提示词可以非常简单，延迟也不高。

提取一批事实后，从每个主体出发，获取与其有关的宾语及关系描述，使用能力稍强的大模型提炼隐藏消息。比如用户吐槽数学考试太难了，可以猜测这位用户是学生且不擅长数学。这也是我们提到的洞见。

将一批事实和洞见再次总结，就得到了我们需要的用户画像。

### 3.15 多级记忆架构

消息上下文采用多级记忆系统，类似于计算机的 L1、L2、L3 缓存：

**L1 - 工作记忆**：包含完整的消息上下文和智能体的思维链

**L2 - 语义索引**：所有被挤出 L1 的 folded 片段的向量化表示。不再将它们的文本直接塞入上下文

**L3 - 长期存档**：非常古老（例如超过一周或数千条消息）的记忆的文本摘要，这是最终的、极度压缩的记忆形式

### 3.16 上下文构建流程

1. **填充 L1**：根据上下文预设逐个填充
2. **检索 L2**：使用最新消息作为查询，在 L2 中进行语义化查找，取出最匹配的 K 条

进一步优化：首先，不是对每条消息都生成向量，而是像常规 RAG 技术一样，将消息记录切割为一定大小的小片段，再以微小片段为最小单元嵌入并存储。这样既可以减少生成成本、存储成本和查询成本，又一定程度上确保了语义的连贯性，插入上下文的片段也是连续且完整的。不然单独几条消息很难有完整的语义，可能搜索结果不是很精确。

关于长期存档，我想将其改造为"日记"，每天固定时间运行一次总结任务，将这一天内所有消息聚合起来，加上智能体的人设背景，以第一人称生成一篇日记。智能体可以随时查阅日记，来了解特定时间发生了什么事。

---
