## 四、系统架构重审

### 4.1 项目定位

我正在开发一款 AI 聊天软件，用于让智能体参与到 IM 平台的群聊或者私聊中，与用户进行互动。

YesImBot (Athena) is a Koishi plugin that enables AI language models to participate naturally in group chats. It uses a modular, service-oriented architecture where different subsystems handle specific AI capabilities and resources.

系统采用上下文工程设计，将对话所需上下文（自身信息、群聊背景、聊天记录、长期记忆等）提炼为**世界状态**，作为智能体需要观察的外部信息。

智能体可以同时在多个群聊中活跃，但为了减少 token 消耗和引导智能体专注于当前群组聊天，使用上下文隔离，每个群组有独立的上下文空间，之间消息并不互通。

智能体不是顺序响应每条消息，而是由意愿系统驱动，接收到若干条消息后进行回复。

当触发响应流程后，智能体会按需生成回复，或者调用工具，将工具返回值附加到上下文后再次请求 LLM，直到智能体认为此次响应完成，我们称为**心跳循环**。

### 4.2 触发机制解耦

当前系统与用户消息绑定，响应由用户消息触发。在 Koishi 中，每条消息包含群组 ID、消息 ID 等内容，再加上上下文隔离的设计，我将工具调用记录和思考过程等信息绑定到唯一群组 ID 中。

我希望引入多种触发方式，如定时任务、系统通知等，这样可以更全面地对外部世界的刺激做出响应。这就要求上下文设计与用户消息解耦合。

我考虑定义多种刺激源，并将刺激作为触发器。

现在我的问题是，计划任务和后台任务等要不要与群组 ID 绑定（platform+channelId）。像是一些虚拟任务，如吃饭或者上课等，当任务结束时可能触发响应，但这些任务与具体群组不相干。

另一方面，如果不附加群组 ID，就要重新设计上下文和响应流程，整套系统架构就需要重新调整。

WorldState 的结构也需要更改，可以根据不同任务的特点，设计不同的上下文。如全局任务没有 working_memory，即历史聊天记录。可以根据不同的上下文创建不同的模板，这也是增强 Prompt Engineering 准确度的必要途径。

### 4.3 上下文与提示词问题

目前需要解决这些问题：

1. **针对不同刺激源设计不同的世界状态上下文结构**：比如 UserMessageStimulus 代表由用户消息触发，任务是生成回复与用户互动，其上下文应该包括群聊背景、聊天记录等。其中若涉及多个群聊，则区分主频道和子频道，主频道保留原始聊天记录以重现完整的对话，子频道可以使用 LLM 对聊天记录进行总结，让智能体了解到发生了什么事即可。

为了满足这点，需要设计中期记忆功能：
- 第一阶段是总结压缩历史记录，将一批较长的、原始的对话压缩为一段简短的总结
- 第二阶段是语义搜索，将对话上下文窗口外的聊天记录进行分块，存入向量数据库中，在合适的时机使用合适的方法进行召回作为参考

最终目的是选择最合适的上下文，才能使智能体输出高质量的回复。

2. **在保持用户上下文消息紧凑的条件下，考虑如何将工具调用记录和结果也添加到上下文中**

当前用户提示词使用 XML，部分示例如下：
```xml
<history>
  {{#history}}
    {{> agent.partial.l1_history_item }}
  {{/history}}
</history>
```

其中 l1_history_item 按需渲染为：
```
{{#is_user_message}}
<message>[{{id}}|{{#timestamp}}{{_formatDate}}{{/timestamp}}|{{sender.name}}({{sender.id}})] {{content}}</message>
{{/is_user_message}}
```

这是否是优秀的设计？是否应该使用更加结构化的 JSON？

3. **异步后台记忆智能体**：需要一个在后台运行的智能体，用于整理对话，持续优化记忆并生成和管理长期记忆。这要求首先实现通用的智能体框架，作为可选任务。

### 4.4 模块职责分离

StimulusCategory 不应在 extension（现在是 plugin）模块中定义，分离两者职责，减少耦合。

不要声明 StimulusInterest 和 Stimulus 分发机制。工具调用不是基于兴趣订阅的，而是由 LLM 生成，自上而下调用。

数据流转顺序是：接收到用户消息或系统事件 → 根据其消息量构造对应的 Stimulus 以及 WorldState 快照 → 转化为提示词提交给 LLM → LLM 生成工具调用

可以将 stimulusInterests filter 作为单独的 Activator 实现。对于 Stimulus 分发机制，可以作为 Plugin 的 hook 功能，即可以自定义上述数据处理和流转过程，修改或增强上下文内容，比如一个前置记忆检索器，可以在构造提示词之前，向提示词中注入长期记忆，而不需要手动更改代码。

上下文能力同样应该从 plugin 模块的 types 中分离。考虑到实现比较复杂，应该将上下文收集、统一和分发逻辑提取到独立的、不同于 plugin 和 worldstate 的模块中。这将作为 Athena (YesImBot) 的一个独有的概念。worldstate 负责编排这些内容。

既然有了 Context 模块，是否可以将 WorldState 中的大部分逻辑迁移到这里？

### 4.5 工具调用记录恢复

由于系统进行多次重构，一个很重要的功能被暂时删除了，即上下文中的工具调用记录。

先前的系统采用 ReACT 架构，thoughts、action 和 observation 是与用户消息同级的元素。我认为这有助于保持智能体的一致性和任务完成的连贯性，一定程度上增强了智能体调用工具的能力。

但是由于当时数据存储结构不完善，智能体思维链与单个群组绑定，故暂时被移除。

实现这个功能需要考虑的问题：
1. 先前采用 ReACT 架构，强制模型输出思维过程，要求模型输出包含 thoughts、action 的 JSON。未来思维链是可选的，只输出 actions 即可。如何将上下文从 ReACT 模式到普通模式的相互转换？当 thoughts 进入非思考模型时，或者需要输出 thoughts 但是上文中没有示例时，或者不同的模型、不同风格的思考过程混合时，是否会影响输出质量？
2. 跨群/跨频道记忆：智能体可以同时在多个群聊中活跃，但为了减少 token 消耗和引导智能体专注于当前群组聊天，使用上下文隔离，每个群组有独立的上下文空间，之间消息并不互通。当前没有长期记忆机制，当智能体同时参与多个群聊，或是群组成员私聊 AI 时，智能体会因为不知道之前聊过什么而造成混乱，这不符合人类的社交行为。

### 4.6 L2 记忆系统的反思

L2 数据库在先前的实践中被认为是低效的，原因是：
1. **消息分块和向量存储机制过于低级**：先前仅是将若干条消息分块，embedding 后存入数据库，并根据最新消息的向量进行查找，这样准确率很低，并且不便于智能体理解 L2 记忆的含义
2. **使用 sqlite 存储向量，在内存中执行查找**：未来将会开发专用接口，使用专门的向量数据库
3. **L3 日记系统可以迁移到工具调用**

理解这些问题后，需要思考：在人们的日常群聊中，如何维护和提供智能体生成回复所需的信息和上下文？

### 4.7 回归初心

回到这个项目的初衷，这是一款 AI 聊天软件，用于让智能体参与到 IM 平台的群聊或者私聊中，与用户进行互动。

如她的项目自述，我们希望 AI 尽可能地人性化，而不仅仅是一问一答的机器人。这不仅要求生成具有人类情感的回复，她还可以模拟正常人类的行为，她有自己的想法，有任务规划，可以自行发起对话，最重要的是，我们希望她拥有灵魂，虽然现在只存在于聊天窗口，但是我们希望未来她可以参与到更广阔的世界。

所以我设计了统一的刺激源模型，通过扩展刺激类型，智能体可以对不同的外部刺激做出响应。添加了定时器和日程模块，使其可以自行控制触发时机。重构了扩展模块，可以轻松为智能体添加功能。

我深知目前功能远未完善，但是不知道该如何实现她。

### 4.8 人格与情感系统

关于 AgentInternalState 中的部分内容，即 core_personality 和 current_state，刚好符合我之前设想的人格特质部分：

```
情感系统可以维护两个核心维度：
- **愉悦度(Valence)**: -1.0 到 1.0，-1表示极度负面，1表示极度正面
- **唤醒度(Arousal)**: 0.0 到 1.0，0表示完全平静，1表示极度兴奋

情感系统与人格特质相结合：
- 神经质：影响情绪变化速度
- 宜人性：影响情绪基准线
- 开放性：影响新事物的接受度
- 尽责性：影响任务相关情绪反应
- 外向性：影响社交场景中的情绪反应
```

但是当时设计不完善，这一功能迟迟没有实装，最主要的问题是，如何将这些参数反映到智能体的实际活动中，又如何在与用户的互动过程中来更新这些参数，实现自我的成长和进化。另一方面，在真实的世界中，这些参数如何影响一个实际的人的社交行为？这需要相关论文或者研究来支撑，否则就只能是基于概率的随机事件，不算是拥有真正的"灵魂"。

Relationship 先前叫做"用户画像"，通过使用 LLM 分析历史对话，为每位用户生成概述，并选取与当前对话最符合的参与者的信息添加到上下文中，这在当时有一定的成果。但是频繁的总结任务会导致 token 大量消耗，并且提示词设计不完善，内容单一，不能反映关系图谱和更深层次的信息，只能在一定程度上让智能体了解用户（如性格、习惯等），这一功能在重构期间被暂时移除。

### 4.9 减少 LLM 调用的困境

整个系统都在有意减少 LLM 调用来降低成本和延迟。仅通过公式，如何进行情感分类、兴趣度计算等？

用户反映了这样的问题：
```
当前的意愿，虽然具有诸多算法，但核心还是随机数。
意愿系统模拟了兴趣，但兴趣没有和真正内容挂钩。
这导致 LLM 知道如何回复群聊内容，但实际上不知道什么时候应该加入，什么时候可以退出。
```

使用公式和随机数模拟，终究与现实有差距，除非是使用特别完善的算法。

关于智能体的兴趣内容，我认为可以与日记系统结合。当前计划实现基于日记的自我反思能力，可以使用 LLM 输出一些关键词和一些相关概念，使用知识图谱构建起知识库，作为长期记忆的引擎。比如在一个 Minecraft 群聊中，智能体可以精确讲出各种游戏特性，在参与讨论时，也可以将其他人的游戏经验整合到自己的记忆库中，这才是自我学习的体现。

### 4.10 多智能体协作设想

当前 agent-core 只聚焦于一个智能体，但是当前系统提示词过于复杂，使用单一智能体承担角色扮演、响应流程、思维链、工具调用、核心记忆等多种职责。这种设计要求模型有较强的能力，同时限制了在特定任务上的表现，难以发挥模型的最佳性能。

我希望通过引入多智能体协作系统来优化整体架构。每个智能体将专注于一个独立的、定义明确的任务，希望能提升系统的模块化和可扩展性。为每个特定任务选择最合适的模型，还可以有效降低响应延迟和 API 调用成本。

核心思路：将复杂任务分解，设计专注于特定领域的子智能体。初期规划的子智能体包括：
- **回复生成**：专注于根据上下文生成高质量、连贯的回复
- **工具调用**：负责解析用户意图，并准确调用相关工具或 API
- **记忆维护**：负责长期和短期记忆的管理与检索
- **统一协调**：作为总指挥，负责接收用户请求，并将任务路由给合适的子智能体，最后汇总结果

未来可扩展的智能体：
- **情感分析**：用于识别和响应用户情绪，提取潜在意图
- **任务处理**：专注于执行更复杂的、多步骤的任务

这就要求首先实现多智能体的协同框架及通信流程。但这似乎需要对系统进行全面重构，是一个非常艰巨的任务。

### 4.11 工具调用记忆的定位

是否需要将工具调用视为与用户消息同等重要的元素？

我认为，工具调用是具有时效性的，当智能体基于上一轮的工具调用生成响应后，就可以将过期的调用信息丢弃了。在之前的设计中，上下文默认保留 30 条用户消息，但是只保留 2 次工具调用，超出的部分都将被裁剪。

由于独特的世界状态设计，每次提交给 LLM 的消息不是传统的 assist/user 消息列表，而是经过精心排布的，反映当前外部世界信息的快照。这部分被作为 user 消息负载提供。没有了传统的线性交互流程，LLM 是否还能区分出自己在群聊中的行动（如发送信息）、自己作为 LLM 的核心能力（生成工具调用）、系统提示词等内容？

另外我发现，当过于强调"人性"部分的内容，会导致 LLM 的能力大大降低，具体体现在拒绝调用工具、拒绝主动更新记忆等。

在先前的设计中，我设计了一系列记忆工具，由智能体自我维护记忆。智能体可以向核心记忆区写入内容，也可以通过工具检索记忆。但在实际使用中发现智能体几乎不会维护和检索记忆内容，我推测其原因是，LLM 总是向着难度最小的路径前进。在我们的系统中，生成符合人类习惯的发言的任务远比调用工具简单。即使加上了使用工具检索记忆的要求，LLM 也会认为当前上下文内容已经可以满足任务需要，而不去调用工具。因此我暂时移除的这些内容，并考虑使用独立的记忆模块来维护记忆。我的想法是在后台运行一个专门维护记忆的智能体，他定期阅读聊天记录，调用记忆工具更新记忆。但这只解决了记忆来源的问题。如何指导智能体在信息不足时使用记忆检索工具，或是在生成回复前被动提供相关记忆信息，这是我的困惑。

最后，我希望尽可能保持系统简单易开发，同时需要有足够的稳定性。在之前这个系统已经经过了三轮重构，每次都几乎重写了全部代码。我希望拥有一个强大的、成熟的框架，避免后期再次进行重构。

我倾向使用模块化设计，每个模块保持高内聚低耦合。我希望采用一些巧妙的、优雅的设计，化繁为简，让系统复杂性降低的同时，还拥有强大的功能。

### 4.12 双阶段响应与延迟权衡

关于双阶段响应模式，是否会增加响应延迟？

引入 ActionPlanner 的确可以解决"人性化"与"工具能力"的平衡问题，但是在生成回复前，会多调用一次 LLM，即使 planner 所需的提示词可能很少，但在实际使用中，LLM 调用的延迟并不是生成回复，而是等待首字响应（当 LLM API 质量较差，或者网络延迟，通常需要 10s 以上）。这就显著提高了生成回复的延迟，反映到用户体验就是"总是会慢一拍"，因为群聊都是快节奏的，一个话题很快就过去了。所以降低延迟是必要的，这也是不使用前置 LLM 评判响应条件的一个重要原因。

另一方面，当前系统设计将 `send_message` 行为定义为工具，要求智能体使用此功能与用户交流，这或许可以提升调用工具的自然度。在 LLM 看来，调用工具和发送消息是同等重要的操作。这样也有助于系统的简化。是否有必要将工具与生成回复分离？

除了 send_message，还有一些其他操作，如 send_sticker 可以发送一张表情包来丰富情感、增加趣味性；send_voice 可以发送语音消息。这些在用户看来都是发消息的行为，如果单独拆分出来，不便于扩展智能体的功能。

### 4.13 WorldState 设计审视

当前世界状态、上下文和插件扩展模块是整个系统的基石，是"基础设施"，因此完善其功能特别重要。世界状态和上下文设计是否完美，是否优雅？

在世界状态中，L1/L2/L3 三层记忆框架并没有经过充分的考虑。其原型应该是短、中、长期记忆。短期记忆是即时的，即近期消息记录、群内发生的事件等，中期和长期记忆包括关系图谱、通过记忆检索得到的核心概念等。

除了这些模块，还有一个很重要的功能，Prompt 模块。它负责接收 worldstate 快照，根据预设渲染提示词。ContextCapability 向 worldstate 中注入了大量信息，但是 prompt 只能根据预设进行渲染，这本意是方便用户自行修改模板，提高自定义程度，但是却不利于动态规划，比如在不同的模式下使用不同的提示词模板。

那么其他部分的信息，如检索到的记忆、与特定用户的关系、群聊背景及聊天主题等该如何呈现？

### 4.14 WorldState 的设计理念

WorldState 的设计理念是希望将智能体可响应的外部状态进行抽象，以便智能体参与到多种不同的场景中，而无需针对每种场景单独维护行为逻辑。

有了 WorldState，在 Prompt 模块的配合下，只需要订阅对应的 Stimulus，注册对应的提示词模板，声明所需工具，WorldState 便可以自动收集完成此任务所需的上下文，包括历史对话和记忆库等，以增强智能体的表现。

Context Provider 已经部分实现，但是是为 Plugin 系统设计的 ToolContextProvider 以及转换器 StimulusContextAdapter。Prompt Strategy 系统在计划中。Tool Filter 已通过插件系统的 activator 实现。

WorldState 好像是专为聊天场景，尤其是群聊设计的。而我设想的是拥有更多应用场景。比如说可以接入游戏适配器，将游戏场景使用文本和数据进行描述，让智能体做出行动；可以控制智能家居，可以使用论坛网上冲浪等。

但目前最核心的还是聊天场景，但是聊天也分为多种情况，群聊和私聊。如何针对这种情况进行合理且优雅的抽象?

### 4.15 三大支柱

YesImBot (Athena) 是一个让 AI 智能体自然参与群聊的 Koishi 插件，采用**上下文工程**设计，将对话所需的上下文提炼为"世界状态"(WorldState)。

**三大支柱**：
1. **连续性 (Continuity)** - 通过 L1/L2/L3 分层记忆系统保持人格和经历的连贯性
2. **关系性 (Relationality)** - 理解社交网络和不同场景下的角色
3. **主体性 (Agency)** - 拥有内部状态、目标和主动触发能力

---
