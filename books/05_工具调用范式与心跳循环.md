## 五、标准工具调用

### 5.1 问题提出

在设计 Agent 时，如何利用模型自身的 tool_call 能力实现 ReACT，而不是使用提示词结构化间接调用工具？即用更标准的 Agentic Loop 来增强现有的 Heartbeat。

目前 Athena 的 Agent 执行逻辑基于 HeartbeatProcessor：每次心跳由 LLM 输出一个自定义 AgentResponse JSON（包含 thoughts、actions[]、request_heartbeat），再由宿主侧顺序执行所有 actions。这会导致：
1. 工具调用协议完全依赖提示词约定，LLM 需要"自己产 JSON"，稳定性受限
2. 同一轮心跳内的工具调用是开环的，工具结果不会回流到当前 LLM 推理中，不利于复杂多步任务

### 5.2 设计理念冲突

我设计的 Agent 更偏向于日常聊天和情感陪伴，因此调用工具不是主要功能。但是为了方便扩展和功能实现统一，我将发送消息也定义为工具，要求 agent 利用此工具与用户交流。换句话说，agent 的每次输出都必须为工具调用，所有行动都必须是工具调用。这种情况下，模型不需要，或者说不能通过 content 输出文本，只能使用工具与外界进行交互，这是否会限制某些模型的能力？

还有一点，OpenAI 规范要求每次工具调用必须提供返回值，其中包括 tool_id 和 content，这意味着 agent 需要参考此次工具调用的结果来规划下一步行动。在我们的系统设计方案中，工具分为两种类型，tool 和 action。tool 用于获取信息，如 get_time、get_weather 等，这些可以归类为传统 tool_call；action 用于具体行动，如 send_message、ban_member 等，一般情况下不需要关心这些行动的返回值，或者没有返回值，也就无需再次触发对话。

### 5.3 非传统消息流设计

这个 agent 服务于多人群聊，因此不是传统一问一答。agent 收到若干条消息后，系统会根据自身状态计算此时的回复意愿值，决定是否触发响应流程。为了避免上下文膨胀，我利用上下文工程设计了每次传递给 LLM 的上下文：
- 系统提示词：包含输出格式、人设性格、可用工具、核心记忆
- 用户输入：当前群聊信息、群成员信息、历史消息

在这种情况下，传统的 system user assistant user ... 消息流就不再适用了，因为当收到新消息时，我们是编辑更新用户输入，而不是添加一条用户消息，这样可以保持上下文高度结构化。同理，助手输出也不会添加到 API 的 message 列表中，而是作为 agent 在群聊中扮演的角色的消息。

### 5.4 工具抽象的意义

为了增强通用性。这不仅是一个 chatbot，更像是一个虚拟生命。将模型表达自身的能力使用工具抽象，可以让她参与到更多的场景中，而不是将内容输出到终端的屏幕上。保留模型的自然文本输出能力，也不是直接用于生成回复，因为我们无法确定需要回复的对象和场景。

我认为这种约束可能会影响模型的输出质量，尤其是生成富有情感的回复。在我看来，模型的工具调用能力是很严谨的，使用原生 tool_call 发送消息可能会使回复风格变得更加死板。所以我倾向于使用结构化文本而不是工具调用。

为了使模型拥有自我认同感和角色一致性，我不使用 assistant 消息来描述智能体的响应，而是将其直接放到与用户的历史交互记录中，以此削弱 AI 的身份，来体现真正的性格。

更关键的问题是，传统的 system user assistant tool 消息流几乎不适用于我们的 Horizon 系统。若通过 messages 列表来管理上下文是非常复杂的。

### 5.5 结构化文本 vs 原生工具调用

模型输出 JSON，代码解析并执行，这也是目前已经实现的做法。

我认为，模型在 tool_call 模式下的行为模式不同，尤其是回复质量方面。目前多数 AI agent/AI IDE/AI 编码插件，如 cline 等，都是通过输出结构化文本来实现的工具调用，比如 cline 使用 XML tag，其评测报告显示各项指标都比 JSON 输出和原生工具调用高得多。

如果原生 tool_call 有优势，那为什么不使用 tool_call 呢？

另一方面，输出结构化文本我可以控制执行细节，并把工具执行逻辑与 ai-provider 分离。比如 ai-sdk 的 generateText 功能，若提供了工具列表，使用 tool_call 方式，generateText 内部会自动请求多次模型，将 tool_result 拼接到 messages 后面，这就导致：
- 工具模块需要与 ai-sdk 耦合，不便于后期迁移到其他请求方式
- 没法控制传递给大模型的上下文内容，上面提到，若调用 action，则代表一轮响应结束，不需要再次拼接调用结果请求大模型。如果使用 tool_call，有调用就一定有结果，generateText 内部会多请求一次大模型，造成资源浪费

正因为我们需要自己解析 tool_calls 数组，才严重依赖 AI SDK 的功能。目前使用结构化文本，模型只需要返回 JSON 内容即可，即使使用最基础的 http post 请求也能完成。

ai-sdk 有一个 streamText 函数，支持对 tool_call 进行更加细粒度的控制；它返回多个流，其中 steps 流的 tool-call 即是工具调用阶段，我们可以注册回调函数来调用我们自己的逻辑。但是这样不仅与工具模块耦合，具体执行模块也要兼容 ai-sdk。

### 5.6 原生 tool_call 的优势分析

预期收益：
1. 不再依赖提示词内的手工 JSON 协议，减少提示词耦合和解析错误
2. 直接利用各大模型对 tools 的原生支持，提升工具调用的准确率和鲁棒性
3. 支持真正闭环的工具调用 -> 结果回流 -> 下一步决策，更适合复杂任务

### 5.7 执行流程设计

一次输出中，所有工具顺序执行，若调用了 tool，则将结果放进上下文中，再次请求模型。

设想的 send_message 不会发生，因为模型明确知道自己要靠 get_weather/get_time 获取信息，才能生成 send_message 要求的内容。

所以这个流程是：
```
第一次输出
1. get_weather
2. get_time
顺序执行1，2，将结果添加进上下文（工作记忆），请求api

第二次输出
1. send_message
回合结束
```

### 5.8 上下文格式问题

这正是之前不使用 tool_call 的原因之一，一旦启用了 tool_call，tool_result 就必须以 role: tool 提供。而在我们的系统中，工具调用结果被放在 system prompt 的"工作记忆"部分。我们能否采用原有设计，将工具调用放进工作记忆？

另外测试中我发现，部分模型在工具调用时仍会通过 content 输出文本，但在我们的系统中，模型与用户交互必须通过工具，这也是我担心使用工具会限制模型表达的原因。

### 5.9 content 输出问题

即使明确声明了只能通过工具交互，禁止使用 content 输出内容，模型依然会同时输出 content 和 tool-call，这说明输出 content 是模型的默认能力。不是必须要求模型只能调用工具，而是输出文本毫无意义，还不如不输出。另外若模型选择不调用工具只输出内容该怎么办？

之前提到，我们不是构建一个功能强大的任务型智能体，而是打造一个虚拟伙伴，为其赋予灵魂。所以回复的自然度特别重要。

thoughts 字段本身就是可选的，它和 actions 一样会进入工作记忆中，每回合结束后清空。assistant.content 可以作为 thoughts，但是应该如何使模型理解 content 的要求？

我认为通过工具调用更死板，是因为模型训练的数据集中可能没有通过调用工具与用户交流的场景。专门测试 agent 的任务数据集中，大多是代码任务或者定火车票安排行程这些。这些任务不需要过多交流，只用完成后通过输出 content 向用户报告即可。我担心会因为训练不足和工具特化导致 tool_call 不如结构化输出。

### 5.10 Token 消耗分析

分析请求参数，toolCall 只增加了 tools 这个参数，可能是模型内部的特殊 token 编码，比如把 tool schema 编码为特殊的工具格式。但是经多轮对话测试发现，token 消耗与消息数量呈正相关，不仅是传入 tools 所占据那部分 token，比如 7 steps 交互，token 消耗量可以达到 5-6k。

response.request 所展示的 messages 即我们提供的提示词和工具调用，没有其他内容。

工具描述本身并没有占据太多内容，问题核心可能在于工具模板，包括输入和输出的格式。在我们的系统中，我们可以自由改变工具的呈现格式，以及工具结果的格式，可以使用紧凑的格式来减少 token 消耗，而 tool_call 只能使用完整的、严谨的工具模板，token 利用效率比较低。

### 5.11 Issue 回应

提出这个问题的根本，是有人提了相关 issue：

> Feature: 是否考虑用更标准的 Agentic Loop 来增强现有的 Heartbeat
>
> 目前 Athena 的 Agent 执行逻辑基于 HeartbeatProcessor：每次心跳由 LLM 输出一个自定义 AgentResponse JSON（包含 thoughts、actions[]、request_heartbeat），再由宿主侧顺序执行所有 actions。
> 1. 工具调用协议完全依赖提示词约定，LLM 需要"自己产 JSON"，稳定性受限；
> 2. 同一轮心跳内的工具调用是开环的，工具结果不会回流到当前 LLM 推理中，不利于复杂多步任务。

项目的初衷就是为智能体赋予"灵魂"，旨在让人工智能大模型能够自然地参与到群聊讨论中，模拟真实的人类互动体验。

闭环 tool 结果回流实际上应该算是实现的，在一个回合中，上一步工具执行结果会作为工作记忆附加到上下文中，并有相关提示"这是你刚才调用工具的结果，请根据这些信息继续行动："

---
